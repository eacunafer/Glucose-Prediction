{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4e3bf4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import xml.etree.cElementTree as et\n",
    "from datetime import datetime\n",
    "from pandas.core.tools.datetimes import to_datetime\n",
    "\n",
    "from datetime import timedelta\n",
    "from RNN import RNN\n",
    "from Transformer import Transformer\n",
    "\n",
    "from utils import series_to_supervised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "82d5a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml_data(filename, selected_items):\n",
    "  tree=et.parse(filename)\n",
    "  root=tree.getroot()\n",
    "  #extract selected items\n",
    "  for child in root:\n",
    "    if child.tag in selected_items:\n",
    "      df = pd.DataFrame()\n",
    "      for elem in child:      \n",
    "        df1 = pd.DataFrame(elem.attrib, index=[0])\n",
    "        #df = df.append(df1)\n",
    "        df = pd.concat([df, df1])\n",
    "      #First column is the timestamp (dayfirst)      \n",
    "      #df.iloc[:,0] = pd.to_datetime(df.iloc[:,0], dayfirst=True)\n",
    "      #write to csv file using the timestamp as index      \n",
    "      df.to_csv(child.tag+'.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4b8ac655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ts_file(filename):\n",
    "  #reads csv file where the first column is a timestamp and the index column\n",
    "  df = pd.read_csv (filename, parse_dates=[0], dayfirst=True, index_col=0)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a6aec7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timedf(df):\n",
    "  #creates a 5 minute interval timeseries dataframe based in index of df\n",
    "  # df must have a timestamp index\n",
    "  #time_df: result dataframe with timestamp index\n",
    "  timestamp = pd.date_range(start=df.index[0], end=df.index[-1]  + timedelta(minutes=4), freq='5T')\n",
    "  time_df = pd.DataFrame({'timestamp':timestamp})\n",
    "  time_df.set_index('timestamp', inplace=True)\n",
    "  return time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e63747f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gaps(df, greaterthan=5, units='m'):\n",
    "  # find gaps relative to index, index must be a datetime field\n",
    "  # greaterthan is the number of time units to be considered a gap\n",
    "  # units 'm'=minutes, 'h'=hours\n",
    "  i = 0\n",
    "  gaps_df = pd.DataFrame()\n",
    "  while i < len(df) - 1:\n",
    "    ts = df.index[i]\n",
    "    next_ts = df.index[i+1]\n",
    "    duration = next_ts - ts\n",
    "    if duration > np.timedelta64(greaterthan, units): \n",
    "      begin_gap = ts\n",
    "      end_gap = next_ts\n",
    "      gaps_df = gaps_df.append({'From': begin_gap, 'To': end_gap, 'Duration': duration}, ignore_index=True)\n",
    "    i = i + 1\n",
    "  gaps_df.sort_values(by=['Duration'], ascending=False, inplace=True)\n",
    "  return gaps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2fc94af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_mean(df, column, by='hour'):\n",
    "  # impute with mean by hours\n",
    "  # in the future by could be another mean grouping criterion\n",
    "  df[by] = df.index.hour\n",
    "  df[column] = df.groupby(by)[column].apply(lambda x: x.fillna(x.mean()))\n",
    "  df.drop(by, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3b4e9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time series into supervised learning problem\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars=1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a80c184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_items = ['glucose_level','bolus','meal']\n",
    "read_xml_data(filename='c://aadm/563-ws-training.xml', selected_items=['glucose_level','bolus','meal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "04bb995e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12124.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>146.07712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>49.68904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>40.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>108.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>140.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>177.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>400.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           glucose\n",
       "count  12124.00000\n",
       "mean     146.07712\n",
       "std       49.68904\n",
       "min       40.00000\n",
       "25%      108.00000\n",
       "50%      140.00000\n",
       "75%      177.00000\n",
       "max      400.00000"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glucose_train = read_ts_file('glucose_level.csv')\n",
    "glucose_train.rename(columns={\"ts\": \"timestamp\", \"value\": \"glucose\"}, inplace=True)\n",
    "glucose_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e662dfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing intervals:  974\n"
     ]
    }
   ],
   "source": [
    "#Finding the length of the complete time series\n",
    "time_df = timedf(glucose_train)\n",
    "print('Missing intervals: ', len(time_df) - len(glucose_train) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cc11d6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-13 12:30:00</th>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-13 12:35:00</th>\n",
       "      <td>229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-13 12:40:00</th>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-13 12:45:00</th>\n",
       "      <td>221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-13 12:50:00</th>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     glucose\n",
       "ts                          \n",
       "2021-09-13 12:30:00    219.0\n",
       "2021-09-13 12:35:00    229.0\n",
       "2021-09-13 12:40:00    224.0\n",
       "2021-09-13 12:45:00    221.0\n",
       "2021-09-13 12:50:00    215.0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding NA in the whole range of cgm-training\n",
    "glucose_miss=glucose_train.resample('5T').mean()\n",
    "glucose_miss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f8482289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13098.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>151.670453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>65.752426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>24.650677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>141.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.081294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            glucose\n",
       "count  13098.000000\n",
       "mean     151.670453\n",
       "std       65.752426\n",
       "min       24.650677\n",
       "25%      109.000000\n",
       "50%      141.000000\n",
       "75%      180.000000\n",
       "max      570.081294"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #mean imputation\n",
    "#impute_mean(glucose_miss, 'glucose')\n",
    "#glucose_train=glucose_miss\n",
    "glucose_train= glucose_miss.interpolate(method=\"spline\",order=3)\n",
    "glucose_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "98e4cecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -10.198214\n",
      "p-value: 0.000000\n",
      "Critical Values:\n",
      "\t1%: -3.431\n",
      "\t5%: -2.862\n",
      "\t10%: -2.567\n"
     ]
    }
   ],
   "source": [
    "#Dickey-Fuller Test\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "X = glucose_train.glucose.values\n",
    "result = adfuller(X)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "\tprint('\\t%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e347e292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of KPSS Test:\n",
      "Test Statistic            0.466732\n",
      "p-value                   0.049159\n",
      "#Lags Used               69.000000\n",
      "Critical Value (10%)      0.347000\n",
      "Critical Value (5%)       0.463000\n",
      "Critical Value (2.5%)     0.574000\n",
      "Critical Value (1%)       0.739000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Function to print out results in customised manner\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "def kpss_test(timeseries):\n",
    "    print ('Results of KPSS Test:')\n",
    "    kpsstest = kpss(timeseries, regression='c', nlags=\"auto\")\n",
    "    kpss_output = pd.Series(kpsstest[0:3], index=['Test Statistic','p-value','#Lags Used'])\n",
    "    for key,value in kpsstest[3].items():\n",
    "        kpss_output['Critical Value (%s)'%key] = value\n",
    "    print (kpss_output)\n",
    "kpss_test(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "02a41964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#glucose_train= glucose_train.interpolate(method=\"spline\",order=3)\n",
    "#glucose_train.describe()\n",
    "glucose_train.head()\n",
    "glucose_train['glucose']=glucose_train['glucose'].diff().diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7970cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # spline smoothing\n",
    "# import rpy2\n",
    "# import rpy2.rinterface\n",
    "# %load_ext rpy2.ipython\n",
    "# import rpy2.robjects as robjects\n",
    "# from rpy2.robjects.packages import importr\n",
    "# splines = importr('splines') \n",
    "# x_train=np.arange(len(glucose_train))\n",
    "# y_train=glucose_train['glucose']\n",
    "# r_y = robjects.FloatVector(y_train)\n",
    "# r_x = robjects.FloatVector(x_train)\n",
    "# r_smooth_spline = robjects.r['smooth.spline'] #extract R function# run smoothing function\n",
    "# spline1 = r_smooth_spline(x=r_x,y=r_y, spar=.01)\n",
    "# ySpline=np.array(robjects.r['predict'](spline1,robjects.FloatVector(x_train)).rx2('y'))\n",
    "# # print(ySpline)\n",
    "# # plt.figure(figsize=(12,6))\n",
    "# # plt.scatter(x_train,y_train,c=\"blue\")\n",
    "# # plt.plot(x_train,ySpline,c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "791b0113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Imputation using Kalman smoothing and spline smoothing\n",
    "# from tsmoothie.smoother import *\n",
    "# from tsmoothie.utils_func import create_windows\n",
    "# #smoother1 = SplineSmoother(n_knots=100, spline_type='cubic_spline')\n",
    "# #smoother1.smooth(cgmtrainclean[['glucose']].T)\n",
    "# smoother = KalmanSmoother(component='level_season', \n",
    "#                           component_noise={'level':0.1, 'season':0.1},n_seasons=7)\n",
    "# smoother.smooth(glucose_miss[['glucose']].T)\n",
    "# glucosekf=smoother.smooth_data[0]\n",
    "# glucose_train=glucose_miss\n",
    "# glucose_train['glucose']=glucosekf\n",
    "# glucose_train['glucose']=ySpline\n",
    "# #smoother1.smooth_data[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a10bb357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_items = ['glucose_level',\"bolus','meal']\n",
    "read_xml_data(filename='c://aadm/591-ws-testing.xml', selected_items=['glucose_level','bolus','meal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0197b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "glucose_test = read_ts_file('glucose_level.csv')\n",
    "glucose_test.rename(columns={\"ts\": \"timestamp\", \"value\": \"glucose\"}, inplace=True)\n",
    "max=glucose_test.max()\n",
    "min=glucose_test.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97ede76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing intervals:  87\n"
     ]
    }
   ],
   "source": [
    "#Finding the length of the complete time series\n",
    "time_df = timedf(glucose_test)\n",
    "print('Missing intervals: ', len(time_df) - len(glucose_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccf38197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-14 00:00:00</th>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14 00:05:00</th>\n",
       "      <td>282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14 00:10:00</th>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14 00:15:00</th>\n",
       "      <td>277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14 00:20:00</th>\n",
       "      <td>267.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     glucose\n",
       "ts                          \n",
       "2022-01-14 00:00:00    283.0\n",
       "2022-01-14 00:05:00    282.0\n",
       "2022-01-14 00:10:00    281.0\n",
       "2022-01-14 00:15:00    277.0\n",
       "2022-01-14 00:20:00    267.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding NA in the whole range of cgm-testing\n",
    "glucose_miss=glucose_test.resample('5T').mean()\n",
    "glucose_miss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a852ddf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-14 00:00:00</th>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14 00:05:00</th>\n",
       "      <td>282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14 00:10:00</th>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14 00:15:00</th>\n",
       "      <td>277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14 00:20:00</th>\n",
       "      <td>267.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     glucose\n",
       "ts                          \n",
       "2022-01-14 00:00:00    283.0\n",
       "2022-01-14 00:05:00    282.0\n",
       "2022-01-14 00:10:00    281.0\n",
       "2022-01-14 00:15:00    277.0\n",
       "2022-01-14 00:20:00    267.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #mean imputation\n",
    "impute_mean(glucose_miss, 'glucose')\n",
    "glucose_test=glucose_miss\n",
    "glucose_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6377b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#glucose_test= glucose_test.interpolate(method=\"spline\",order=3)\n",
    "#glucose_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb73a7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to determine R home: [WinError 2] The system cannot find the file specified\n",
      "C:\\Users\\eacun\\anaconda3\\lib\\site-packages\\rpy2\\robjects\\packages.py:367: UserWarning: The symbol 'quartz' is not in this R namespace/package.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# spline smoothing\n",
    "import rpy2\n",
    "import rpy2.rinterface\n",
    "%load_ext rpy2.ipython\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "splines = importr('splines') \n",
    "x_train=np.arange(len(glucose_test))\n",
    "y_train=glucose_test['glucose']\n",
    "r_y = robjects.FloatVector(y_train)\n",
    "r_x = robjects.FloatVector(x_train)\n",
    "r_smooth_spline = robjects.r['smooth.spline'] #extract R function# run smoothing function\n",
    "spline1 = r_smooth_spline(x=r_x,y=r_y, spar=.01)\n",
    "ySpline=np.array(robjects.r['predict'](spline1,robjects.FloatVector(x_train)).rx2('y'))\n",
    "# print(ySpline)\n",
    "# plt.figure(figsize=(12,6))\n",
    "# plt.scatter(x_train,y_train,c=\"blue\")\n",
    "# plt.plot(x_train,ySpline,c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4e377ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Imputation using Kalman smoothing and spline smoothing\n",
    "# from tsmoothie.smoother import *\n",
    "# from tsmoothie.utils_func import create_windows\n",
    "# #smoother1 = SplineSmoother(n_knots=100, spline_type='cubic_spline')\n",
    "# #smoother1.smooth(cgmtrainclean[['glucose']].T)\n",
    "# smoother = KalmanSmoother(component='level_season', \n",
    "#                           component_noise={'level':0.1, 'season':0.1},n_seasons=7)\n",
    "# smoother.smooth(glucose_miss[['glucose']].T)\n",
    "# glucosekf=smoother.smooth_data[0]\n",
    "# glucose_test=glucose_miss\n",
    "# glucose_test['glucose']=glucosekf\n",
    "glucose_test['glucose']=ySpline\n",
    "# #smoother1.smooth_data[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9a762f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glucose    291\n",
      "dtype: int64 glucose    43\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Normalizing the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "datatrain = np.array(glucose_train.values.astype('float32'))\n",
    "datatest = np.array(glucose_test.values.astype('float32'))\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "datatrain = scaler.fit_transform(datatrain).flatten()\n",
    "datatest = scaler.fit_transform(datatest).flatten()\n",
    "#n = len(data)\n",
    "train_data=pd.DataFrame(datatrain)\n",
    "test_data=pd.DataFrame(datatest)\n",
    "print(max,min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d13796ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12738, 6)\n",
      "test shape: (2830, 12)\n",
      "(12738, 12, 1) (2830, 12, 1)\n",
      "(12738, 6)\n"
     ]
    }
   ],
   "source": [
    "data1=series_to_supervised(train_data, n_in=12, n_out=6, dropnan=True)\n",
    "data2=series_to_supervised(test_data, n_in=12, n_out=6, dropnan=True)\n",
    "train=data1.values\n",
    "X_train,y_train=train[:, 0:12],train[:, 12:]\n",
    "test=data2.values\n",
    "X_test,y_test=test[:, 0:12],test[:, 12:]\n",
    "ytest=y_test\n",
    "print(y_train.shape)\n",
    "print(\"test shape:\",X_test.shape)\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "X_train_reshaped = X_train.reshape((-1,12,1))\n",
    "X_test_reshaped = X_test.reshape((-1,12,1))\n",
    "print(X_train_reshaped.shape,X_test_reshaped.shape)\n",
    "y_train_reshaped = y_train\n",
    "print(y_train_reshaped.shape)\n",
    "y_test_reshaped = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "999a1a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the RNN-LSTM\n",
    "#rnn = RNN()\n",
    "#rnn.train(X_train_reshaped,y_train_reshaped)\n",
    "#_, rmse_result, mae_result, smape_result, r2_result = rnn.evaluate(X_test_reshaped,y_test_reshaped,max,min)\n",
    "#print('Result \\n RMSE = %.2f  \\n MAE = %.2f \\n R2 = %.1f [%%]' % (rmse_result,\n",
    "#                                                                            mae_result,                                                                          \n",
    "#                                                                            r2_result*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "248f1d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 12, 2)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 12, 2)       4           ['input_1[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 12, 2)       11266       ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 12, 2)        0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 12, 2)       0           ['dropout[0][0]',                \n",
      " da)                                                              'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 12, 2)       4           ['tf.__operators__.add[0][0]']   \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 12, 4)        12          ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 12, 4)        0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 12, 2)        10          ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 12, 2)       0           ['conv1d_1[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 12, 2)       4           ['tf.__operators__.add_1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 12, 2)       11266       ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 12, 2)        0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 12, 2)       0           ['dropout_2[0][0]',              \n",
      " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 12, 2)       4           ['tf.__operators__.add_2[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 12, 4)        12          ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 12, 4)        0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 12, 2)        10          ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 12, 2)       0           ['conv1d_3[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 12, 2)       4           ['tf.__operators__.add_3[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 12, 2)       11266       ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 12, 2)        0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 12, 2)       0           ['dropout_4[0][0]',              \n",
      " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 12, 2)       4           ['tf.__operators__.add_4[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 12, 4)        12          ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 12, 4)        0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 12, 2)        10          ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 12, 2)       0           ['conv1d_5[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 12, 2)       4           ['tf.__operators__.add_5[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 12, 2)       11266       ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 12, 2)        0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 12, 2)       0           ['dropout_6[0][0]',              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 12, 2)       4           ['tf.__operators__.add_6[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 12, 4)        12          ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 12, 4)        0           ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 12, 2)        10          ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 12, 2)       0           ['conv1d_7[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 12)          0           ['tf.__operators__.add_7[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          1664        ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 6)            774         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 47,622\n",
      "Trainable params: 47,622\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 12, 2) for input KerasTensor(type_spec=TensorSpec(shape=(None, 12, 2), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 12, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\eacun\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\eacun\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\eacun\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\eacun\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\eacun\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"layer_normalization\" (type LayerNormalization).\n    \n    Dimension 2 in both shapes must be equal, but are 2 and 1. Shapes are [?,12,2] and [?,12,1].\n    \n    Call arguments received by layer \"layer_normalization\" (type LayerNormalization):\n      • inputs=tf.Tensor(shape=(None, 12, 1), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m look_back \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m\n\u001b[0;32m      5\u001b[0m tr \u001b[38;5;241m=\u001b[39m Transformer()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train_reshaped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m a\u001b[38;5;241m=\u001b[39mtr\u001b[38;5;241m.\u001b[39mevaluate(X_test_reshaped,y_test_reshaped)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(a)\n",
      "File \u001b[1;32m~\\DMML\\Transformer.py:149\u001b[0m, in \u001b[0;36mTransformer.train\u001b[1;34m(self, X_train, y_train, epochs, batch_size)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m#filepath = self.checkpoint_dir+\"/Transformer.best\"+datetime.now().strftime('%d%m%Y_%H:%M:%S')+\".hdf5\"\u001b[39;00m\n\u001b[0;32m    147\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(filepath, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 149\u001b[0m callback_history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;66;43;03m#validation_split=0.2,\u001b[39;49;00m\n\u001b[0;32m    151\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_monitor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file72n4dwnt.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\eacun\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\eacun\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\eacun\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\eacun\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\eacun\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"layer_normalization\" (type LayerNormalization).\n    \n    Dimension 2 in both shapes must be equal, but are 2 and 1. Shapes are [?,12,2] and [?,12,1].\n    \n    Call arguments received by layer \"layer_normalization\" (type LayerNormalization):\n      • inputs=tf.Tensor(shape=(None, 12, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Testing the Transformer\n",
    "import time\n",
    "start_time = time.time()\n",
    "look_back = 12\n",
    "tr = Transformer()\n",
    "tr.train(X_train_reshaped,y_train_reshaped)\n",
    "a=tr.evaluate(X_test_reshaped,y_test_reshaped)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726fffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max=np.array(max)\n",
    "min=np.array(min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9078775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Denormalizing prediction\n",
    "forec1=a*(max-min)+min\n",
    "print(forec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffe53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Denomalizing the actual values\n",
    "actual=ytest*(max-min)+min\n",
    "print(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb930566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing the RMSE\n",
    "forec1=np.array(forec1)\n",
    "actual=np.array(actual)\n",
    "diff=actual-forec1\n",
    "#print(diff.shape)\n",
    "#np.sqrt(np.mean((diff)**2,axis=0))\n",
    "print(\"RMSE:\",np.sqrt(np.mean((diff)**2,axis=0)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a76e84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc63a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
