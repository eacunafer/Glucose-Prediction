{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e3bf4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import xml.etree.cElementTree as et\n",
    "from datetime import datetime\n",
    "from pandas.core.tools.datetimes import to_datetime\n",
    "\n",
    "from datetime import timedelta\n",
    "from RNN import RNN\n",
    "from Transformer import Transformer\n",
    "\n",
    "#from utils import series_to_supervised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82d5a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml_data(filename, selected_items):\n",
    "  tree=et.parse(filename)\n",
    "  root=tree.getroot()\n",
    "  #extract selected items\n",
    "  for child in root:\n",
    "    if child.tag in selected_items:\n",
    "      df = pd.DataFrame()\n",
    "      for elem in child:      \n",
    "        df1 = pd.DataFrame(elem.attrib, index=[0])\n",
    "        #df = df.append(df1)\n",
    "        df = pd.concat([df, df1])\n",
    "      #First column is the timestamp (dayfirst)      \n",
    "      #df.iloc[:,0] = pd.to_datetime(df.iloc[:,0], dayfirst=True)\n",
    "      #write to csv file using the timestamp as index      \n",
    "      df.to_csv(child.tag+'.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b8ac655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ts_file(filename):\n",
    "  #reads csv file where the first column is a timestamp and the index column\n",
    "  df = pd.read_csv (filename, parse_dates=[0], dayfirst=True, index_col=0)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f611f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_items = ['glucose_level','bolus','meal']\n",
    "read_xml_data(filename='c://aadm/584-ws-training.xml', selected_items=['glucose_level','bolus','meal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8532d8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>192.484444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>65.442789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>145.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>183.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>230.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            glucose\n",
       "count  12150.000000\n",
       "mean     192.484444\n",
       "std       65.442789\n",
       "min       40.000000\n",
       "25%      145.000000\n",
       "50%      183.000000\n",
       "75%      230.000000\n",
       "max      400.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glucose_train = read_ts_file('glucose_level.csv')\n",
    "glucose_train.rename(columns={\"ts\": \"timestamp\", \"value\": \"glucose\"}, inplace=True)\n",
    "glucose_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c078821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timedf(df):\n",
    "  #creates a 5 minute interval timeseries dataframe based in index of df\n",
    "  # df must have a timestamp index\n",
    "  #time_df: result dataframe with timestamp index\n",
    "  timestamp = pd.date_range(start=df.index[0], end=df.index[-1]  + timedelta(minutes=4), freq='5T')\n",
    "  time_df = pd.DataFrame({'timestamp':timestamp})\n",
    "  time_df.set_index('timestamp', inplace=True)\n",
    "  return time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e63747f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gaps(df, greaterthan=5, units='m'):\n",
    "  # find gaps relative to index, index must be a datetime field\n",
    "  # greaterthan is the number of time units to be considered a gap\n",
    "  # units 'm'=minutes, 'h'=hours\n",
    "  i = 0\n",
    "  gaps_df = pd.DataFrame()\n",
    "  while i < len(df) - 1:\n",
    "    ts = df.index[i]\n",
    "    next_ts = df.index[i+1]\n",
    "    duration = next_ts - ts\n",
    "    if duration > np.timedelta64(greaterthan, units): \n",
    "      begin_gap = ts\n",
    "      end_gap = next_ts\n",
    "      gaps_df = gaps_df.append({'From': begin_gap, 'To': end_gap, 'Duration': duration}, ignore_index=True)\n",
    "    i = i + 1\n",
    "  gaps_df.sort_values(by=['Duration'], ascending=False, inplace=True)\n",
    "  return gaps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b4e9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time series into supervised learning problem\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars=1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e662dfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing intervals:  1098\n"
     ]
    }
   ],
   "source": [
    "#Finding the length of the complete time series\n",
    "time_df = timedf(glucose_train)\n",
    "print('Missing intervals: ', len(time_df) - len(glucose_train) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc11d6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-05-14 00:00:00</th>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-14 00:05:00</th>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-14 00:10:00</th>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-14 00:15:00</th>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-14 00:20:00</th>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     glucose\n",
       "ts                          \n",
       "2025-05-14 00:00:00     48.0\n",
       "2025-05-14 00:05:00     48.0\n",
       "2025-05-14 00:10:00     53.0\n",
       "2025-05-14 00:15:00     63.0\n",
       "2025-05-14 00:20:00     69.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding NA in the whole range of cgm-training\n",
    "glucose_train=glucose_train.resample('5T').mean()\n",
    "glucose_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a10bb357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_items = ['glucose_level',\"bolus','meal']\n",
    "read_xml_data(filename='c://aadm/584-ws-testing.xml', selected_items=['glucose_level','bolus','meal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0197b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "glucose_test = read_ts_file('glucose_level.csv')\n",
    "glucose_test.rename(columns={\"ts\": \"timestamp\", \"value\": \"glucose\"}, inplace=True)\n",
    "max=glucose_test.max()\n",
    "min=glucose_test.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97ede76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing intervals:  331\n"
     ]
    }
   ],
   "source": [
    "#Finding the length of the complete time series\n",
    "time_df = timedf(glucose_test)\n",
    "print('Missing intervals: ', len(time_df) - len(glucose_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccf38197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-06-29 00:00:00</th>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-29 00:05:00</th>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-29 00:10:00</th>\n",
       "      <td>262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-29 00:15:00</th>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-29 00:20:00</th>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     glucose\n",
       "ts                          \n",
       "2025-06-29 00:00:00    243.0\n",
       "2025-06-29 00:05:00    253.0\n",
       "2025-06-29 00:10:00    262.0\n",
       "2025-06-29 00:15:00    269.0\n",
       "2025-06-29 00:20:00    269.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding NA in the whole range of cgm-testing\n",
    "glucose_test=glucose_test.resample('5T').mean()\n",
    "glucose_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9a762f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glucose    400\n",
      "dtype: int64 glucose    41\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Normalizing the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "datatrain = np.array(glucose_train.values.astype('float32'))\n",
    "datatest = np.array(glucose_test.values.astype('float32'))\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "datatrain = scaler.fit_transform(datatrain).flatten()\n",
    "datatest = scaler.fit_transform(datatest).flatten()\n",
    "#n = len(data)\n",
    "train_data=pd.DataFrame(datatrain)\n",
    "test_data=pd.DataFrame(datatest)\n",
    "print(max,min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d13796ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11150, 6)\n",
      "test shape: (2393, 12)\n",
      "(11150, 12, 1) (2393, 12, 1)\n",
      "(11150, 6)\n"
     ]
    }
   ],
   "source": [
    "data1=series_to_supervised(train_data, n_in=12, n_out=6, dropnan=True)\n",
    "data2=series_to_supervised(test_data, n_in=12, n_out=6, dropnan=True)\n",
    "train=data1.values\n",
    "X_train,y_train=train[:, 0:12],train[:, 12:]\n",
    "test=data2.values\n",
    "X_test,y_test=test[:, 0:12],test[:, 12:]\n",
    "ytest=y_test\n",
    "print(y_train.shape)\n",
    "print(\"test shape:\",X_test.shape)\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "X_train_reshaped = X_train.reshape((-1,12,1))\n",
    "X_test_reshaped = X_test.reshape((-1,12,1))\n",
    "print(X_train_reshaped.shape,X_test_reshaped.shape)\n",
    "y_train_reshaped = y_train\n",
    "print(y_train_reshaped.shape)\n",
    "y_test_reshaped = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "999a1a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the RNN-LSTM\n",
    "#rnn = RNN()\n",
    "#rnn.train(X_train_reshaped,y_train_reshaped)\n",
    "#_, rmse_result, mae_result, smape_result, r2_result = rnn.evaluate(X_test_reshaped,y_test_reshaped,max,min)\n",
    "#print('Result \\n RMSE = %.2f  \\n MAE = %.2f \\n R2 = %.1f [%%]' % (rmse_result,\n",
    "#                                                                            mae_result,                                                                          \n",
    "#                                                                            r2_result*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "248f1d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 12, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 12, 1)       2           ['input_1[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 12, 1)       7169        ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 12, 1)        0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 12, 1)       0           ['dropout[0][0]',                \n",
      " da)                                                              'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 12, 1)       2           ['tf.__operators__.add[0][0]']   \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 12, 4)        8           ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 12, 4)        0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 12, 1)        5           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 12, 1)       0           ['conv1d_1[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 12, 1)       2           ['tf.__operators__.add_1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 12, 1)       7169        ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 12, 1)        0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 12, 1)       0           ['dropout_2[0][0]',              \n",
      " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 12, 1)       2           ['tf.__operators__.add_2[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 12, 4)        8           ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 12, 4)        0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 12, 1)        5           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 12, 1)       0           ['conv1d_3[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 12, 1)       2           ['tf.__operators__.add_3[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 12, 1)       7169        ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 12, 1)        0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 12, 1)       0           ['dropout_4[0][0]',              \n",
      " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 12, 1)       2           ['tf.__operators__.add_4[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 12, 4)        8           ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 12, 4)        0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 12, 1)        5           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 12, 1)       0           ['conv1d_5[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 12, 1)       2           ['tf.__operators__.add_5[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 12, 1)       7169        ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 12, 1)        0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 12, 1)       0           ['dropout_6[0][0]',              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 12, 1)       2           ['tf.__operators__.add_6[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 12, 4)        8           ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 12, 4)        0           ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 12, 1)        5           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 12, 1)       0           ['conv1d_7[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 12)          0           ['tf.__operators__.add_7[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          1664        ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 6)            774         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,182\n",
      "Trainable params: 31,182\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0854 - rmse: 0.2824 - mae: 0.2180 - smape: 35.7808 - coeff_determination: -1.6871WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.08537, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 25s 121ms/step - loss: 0.0854 - rmse: 0.2817 - mae: 0.2178 - smape: 35.7635 - coeff_determination: -1.6789\n",
      "Epoch 2/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0321 - rmse: 0.1786 - mae: 0.1348 - smape: 18.7082 - coeff_determination: -0.0234WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 2: loss improved from 0.08537 to 0.03210, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 21s 122ms/step - loss: 0.0321 - rmse: 0.1784 - mae: 0.1348 - smape: 18.7049 - coeff_determination: -0.0314\n",
      "Epoch 3/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0240 - rmse: 0.1545 - mae: 0.1164 - smape: 15.6359 - coeff_determination: 0.2352WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 3: loss improved from 0.03210 to 0.02403, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 0.0240 - rmse: 0.1544 - mae: 0.1164 - smape: 15.6383 - coeff_determination: 0.2367\n",
      "Epoch 4/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0195 - rmse: 0.1391 - mae: 0.1047 - smape: 13.7770 - coeff_determination: 0.3805WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 4: loss improved from 0.02403 to 0.01948, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 124ms/step - loss: 0.0195 - rmse: 0.1390 - mae: 0.1047 - smape: 13.7732 - coeff_determination: 0.3812\n",
      "Epoch 5/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0158 - rmse: 0.1251 - mae: 0.0938 - smape: 12.1516 - coeff_determination: 0.4968WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 5: loss improved from 0.01948 to 0.01577, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 0.0158 - rmse: 0.1252 - mae: 0.0939 - smape: 12.1535 - coeff_determination: 0.4931\n",
      "Epoch 6/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0134 - rmse: 0.1152 - mae: 0.0860 - smape: 11.0787 - coeff_determination: 0.5728WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 6: loss improved from 0.01577 to 0.01336, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 129ms/step - loss: 0.0134 - rmse: 0.1151 - mae: 0.0860 - smape: 11.0761 - coeff_determination: 0.5733\n",
      "Epoch 7/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0115 - rmse: 0.1067 - mae: 0.0800 - smape: 10.3108 - coeff_determination: 0.6367WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 7: loss improved from 0.01336 to 0.01146, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 23s 129ms/step - loss: 0.0115 - rmse: 0.1065 - mae: 0.0800 - smape: 10.3069 - coeff_determination: 0.6377\n",
      "Epoch 8/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0104 - rmse: 0.1016 - mae: 0.0761 - smape: 9.8277 - coeff_determination: 0.6672WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 8: loss improved from 0.01146 to 0.01039, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 23s 130ms/step - loss: 0.0104 - rmse: 0.1014 - mae: 0.0761 - smape: 9.8245 - coeff_determination: 0.6675\n",
      "Epoch 9/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0098 - rmse: 0.0987 - mae: 0.0737 - smape: 9.5053 - coeff_determination: 0.6889WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 9: loss improved from 0.01039 to 0.00982, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 23s 130ms/step - loss: 0.0098 - rmse: 0.0985 - mae: 0.0737 - smape: 9.5038 - coeff_determination: 0.6898\n",
      "Epoch 10/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0089 - rmse: 0.0940 - mae: 0.0703 - smape: 9.0953 - coeff_determination: 0.7169WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 10: loss improved from 0.00982 to 0.00890, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 23s 132ms/step - loss: 0.0089 - rmse: 0.0938 - mae: 0.0702 - smape: 9.0916 - coeff_determination: 0.7176\n",
      "Epoch 11/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0084 - rmse: 0.0909 - mae: 0.0676 - smape: 8.7543 - coeff_determination: 0.7353WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 11: loss improved from 0.00890 to 0.00835, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 23s 134ms/step - loss: 0.0083 - rmse: 0.0908 - mae: 0.0676 - smape: 8.7550 - coeff_determination: 0.7351\n",
      "Epoch 12/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0080 - rmse: 0.0890 - mae: 0.0661 - smape: 8.5412 - coeff_determination: 0.7459WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 12: loss improved from 0.00835 to 0.00801, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 21s 123ms/step - loss: 0.0080 - rmse: 0.0890 - mae: 0.0661 - smape: 8.5449 - coeff_determination: 0.7460\n",
      "Epoch 13/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0076 - rmse: 0.0867 - mae: 0.0643 - smape: 8.3546 - coeff_determination: 0.7604WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 13: loss improved from 0.00801 to 0.00758, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 0.0076 - rmse: 0.0865 - mae: 0.0643 - smape: 8.3507 - coeff_determination: 0.7610\n",
      "Epoch 14/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0073 - rmse: 0.0851 - mae: 0.0630 - smape: 8.2077 - coeff_determination: 0.7670WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 14: loss improved from 0.00758 to 0.00733, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 124ms/step - loss: 0.0073 - rmse: 0.0852 - mae: 0.0630 - smape: 8.2080 - coeff_determination: 0.7672\n",
      "Epoch 15/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0072 - rmse: 0.0841 - mae: 0.0621 - smape: 8.0685 - coeff_determination: 0.7730WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 15: loss improved from 0.00733 to 0.00716, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 0.0072 - rmse: 0.0841 - mae: 0.0621 - smape: 8.0695 - coeff_determination: 0.7727\n",
      "Epoch 16/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0069 - rmse: 0.0824 - mae: 0.0610 - smape: 7.9274 - coeff_determination: 0.7805WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 16: loss improved from 0.00716 to 0.00687, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 0.0069 - rmse: 0.0823 - mae: 0.0610 - smape: 7.9256 - coeff_determination: 0.7807\n",
      "Epoch 17/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0067 - rmse: 0.0816 - mae: 0.0601 - smape: 7.7958 - coeff_determination: 0.7861WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 17: loss improved from 0.00687 to 0.00673, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 128ms/step - loss: 0.0067 - rmse: 0.0817 - mae: 0.0602 - smape: 7.7973 - coeff_determination: 0.7835\n",
      "Epoch 18/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0066 - rmse: 0.0811 - mae: 0.0596 - smape: 7.7257 - coeff_determination: 0.7891WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 18: loss improved from 0.00673 to 0.00664, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 128ms/step - loss: 0.0066 - rmse: 0.0810 - mae: 0.0596 - smape: 7.7247 - coeff_determination: 0.7896\n",
      "Epoch 19/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0063 - rmse: 0.0788 - mae: 0.0579 - smape: 7.5449 - coeff_determination: 0.7977WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 19: loss improved from 0.00664 to 0.00631, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 128ms/step - loss: 0.0063 - rmse: 0.0788 - mae: 0.0579 - smape: 7.5438 - coeff_determination: 0.7981\n",
      "Epoch 20/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0062 - rmse: 0.0780 - mae: 0.0570 - smape: 7.4233 - coeff_determination: 0.8027WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 20: loss improved from 0.00631 to 0.00616, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 0.0062 - rmse: 0.0779 - mae: 0.0570 - smape: 7.4215 - coeff_determination: 0.8029\n",
      "Epoch 21/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0059 - rmse: 0.0763 - mae: 0.0559 - smape: 7.2780 - coeff_determination: 0.8122WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 21: loss improved from 0.00616 to 0.00592, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 128ms/step - loss: 0.0059 - rmse: 0.0766 - mae: 0.0559 - smape: 7.2809 - coeff_determination: 0.8110\n",
      "Epoch 22/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0059 - rmse: 0.0761 - mae: 0.0557 - smape: 7.2371 - coeff_determination: 0.8128WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 22: loss improved from 0.00592 to 0.00587, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 0.0059 - rmse: 0.0760 - mae: 0.0557 - smape: 7.2396 - coeff_determination: 0.8133\n",
      "Epoch 23/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0058 - rmse: 0.0756 - mae: 0.0549 - smape: 7.1220 - coeff_determination: 0.8169WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 23: loss improved from 0.00587 to 0.00581, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 128ms/step - loss: 0.0058 - rmse: 0.0755 - mae: 0.0548 - smape: 7.1193 - coeff_determination: 0.8175\n",
      "Epoch 24/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0057 - rmse: 0.0748 - mae: 0.0542 - smape: 7.0501 - coeff_determination: 0.8200WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 24: loss improved from 0.00581 to 0.00569, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 128ms/step - loss: 0.0057 - rmse: 0.0748 - mae: 0.0542 - smape: 7.0506 - coeff_determination: 0.8190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0054 - rmse: 0.0732 - mae: 0.0531 - smape: 6.8899 - coeff_determination: 0.8275WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 25: loss improved from 0.00569 to 0.00544, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 0.0054 - rmse: 0.0732 - mae: 0.0531 - smape: 6.8916 - coeff_determination: 0.8277\n",
      "Epoch 26/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0053 - rmse: 0.0720 - mae: 0.0523 - smape: 6.8163 - coeff_determination: 0.8337WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 26: loss improved from 0.00544 to 0.00526, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 23s 130ms/step - loss: 0.0053 - rmse: 0.0719 - mae: 0.0523 - smape: 6.8153 - coeff_determination: 0.8339\n",
      "Epoch 27/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0053 - rmse: 0.0720 - mae: 0.0521 - smape: 6.7618 - coeff_determination: 0.8316WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00526\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 0.0053 - rmse: 0.0720 - mae: 0.0521 - smape: 6.7628 - coeff_determination: 0.8314\n",
      "Epoch 28/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0051 - rmse: 0.0710 - mae: 0.0514 - smape: 6.6958 - coeff_determination: 0.8362WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 28: loss improved from 0.00526 to 0.00513, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 128ms/step - loss: 0.0051 - rmse: 0.0708 - mae: 0.0514 - smape: 6.6934 - coeff_determination: 0.8361\n",
      "Epoch 29/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0051 - rmse: 0.0711 - mae: 0.0510 - smape: 6.6200 - coeff_determination: 0.8355WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00513\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 0.0051 - rmse: 0.0711 - mae: 0.0510 - smape: 6.6179 - coeff_determination: 0.8358\n",
      "Epoch 30/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0050 - rmse: 0.0699 - mae: 0.0503 - smape: 6.5466 - coeff_determination: 0.8433WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 30: loss improved from 0.00513 to 0.00497, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 0.0050 - rmse: 0.0699 - mae: 0.0503 - smape: 6.5459 - coeff_determination: 0.8434\n",
      "Epoch 31/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0048 - rmse: 0.0688 - mae: 0.0495 - smape: 6.4645 - coeff_determination: 0.8451WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 31: loss improved from 0.00497 to 0.00481, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 128ms/step - loss: 0.0048 - rmse: 0.0687 - mae: 0.0494 - smape: 6.4632 - coeff_determination: 0.8452\n",
      "Epoch 32/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0048 - rmse: 0.0684 - mae: 0.0491 - smape: 6.4044 - coeff_determination: 0.8496WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 32: loss improved from 0.00481 to 0.00476, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 23s 129ms/step - loss: 0.0048 - rmse: 0.0684 - mae: 0.0491 - smape: 6.4063 - coeff_determination: 0.8494\n",
      "Epoch 33/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0046 - rmse: 0.0675 - mae: 0.0486 - smape: 6.3605 - coeff_determination: 0.8522WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 33: loss improved from 0.00476 to 0.00464, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 23s 129ms/step - loss: 0.0046 - rmse: 0.0676 - mae: 0.0486 - smape: 6.3625 - coeff_determination: 0.8505\n",
      "Epoch 34/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0047 - rmse: 0.0679 - mae: 0.0485 - smape: 6.3197 - coeff_determination: 0.8510WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00464\n",
      "175/175 [==============================] - 23s 129ms/step - loss: 0.0047 - rmse: 0.0679 - mae: 0.0485 - smape: 6.3239 - coeff_determination: 0.8508\n",
      "Epoch 35/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0046 - rmse: 0.0672 - mae: 0.0478 - smape: 6.2497 - coeff_determination: 0.8535WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 35: loss improved from 0.00464 to 0.00460, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 128ms/step - loss: 0.0046 - rmse: 0.0672 - mae: 0.0478 - smape: 6.2486 - coeff_determination: 0.8528\n",
      "Epoch 36/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0044 - rmse: 0.0659 - mae: 0.0469 - smape: 6.1602 - coeff_determination: 0.8589WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 36: loss improved from 0.00460 to 0.00444, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 23s 130ms/step - loss: 0.0044 - rmse: 0.0662 - mae: 0.0469 - smape: 6.1638 - coeff_determination: 0.8577\n",
      "Epoch 37/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0044 - rmse: 0.0655 - mae: 0.0466 - smape: 6.1312 - coeff_determination: 0.8614WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 37: loss improved from 0.00444 to 0.00437, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 129ms/step - loss: 0.0044 - rmse: 0.0655 - mae: 0.0466 - smape: 6.1320 - coeff_determination: 0.8617\n",
      "Epoch 38/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0043 - rmse: 0.0647 - mae: 0.0461 - smape: 6.0500 - coeff_determination: 0.8651WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 38: loss improved from 0.00437 to 0.00427, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 23s 129ms/step - loss: 0.0043 - rmse: 0.0647 - mae: 0.0461 - smape: 6.0488 - coeff_determination: 0.8652\n",
      "Epoch 39/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0042 - rmse: 0.0645 - mae: 0.0457 - smape: 6.0110 - coeff_determination: 0.8653WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 39: loss improved from 0.00427 to 0.00425, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 23s 130ms/step - loss: 0.0042 - rmse: 0.0646 - mae: 0.0457 - smape: 6.0129 - coeff_determination: 0.8654\n",
      "Epoch 40/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0042 - rmse: 0.0641 - mae: 0.0453 - smape: 5.9688 - coeff_determination: 0.8665WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 40: loss improved from 0.00425 to 0.00419, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 23s 130ms/step - loss: 0.0042 - rmse: 0.0642 - mae: 0.0453 - smape: 5.9679 - coeff_determination: 0.8664\n",
      "Epoch 41/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0042 - rmse: 0.0639 - mae: 0.0452 - smape: 5.9613 - coeff_determination: 0.8675WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 41: loss improved from 0.00419 to 0.00417, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 23s 130ms/step - loss: 0.0042 - rmse: 0.0639 - mae: 0.0452 - smape: 5.9633 - coeff_determination: 0.8672\n",
      "Epoch 42/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0041 - rmse: 0.0632 - mae: 0.0446 - smape: 5.8848 - coeff_determination: 0.8705WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 42: loss improved from 0.00417 to 0.00408, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 129ms/step - loss: 0.0041 - rmse: 0.0633 - mae: 0.0446 - smape: 5.8878 - coeff_determination: 0.8705\n",
      "Epoch 43/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0041 - rmse: 0.0629 - mae: 0.0444 - smape: 5.8524 - coeff_determination: 0.8709WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 43: loss improved from 0.00408 to 0.00405, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 23s 129ms/step - loss: 0.0041 - rmse: 0.0630 - mae: 0.0444 - smape: 5.8537 - coeff_determination: 0.8698\n",
      "Epoch 44/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0040 - rmse: 0.0627 - mae: 0.0442 - smape: 5.8433 - coeff_determination: 0.8719WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 44: loss improved from 0.00405 to 0.00402, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 23s 132ms/step - loss: 0.0040 - rmse: 0.0627 - mae: 0.0442 - smape: 5.8435 - coeff_determination: 0.8719\n",
      "Epoch 45/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0039 - rmse: 0.0617 - mae: 0.0433 - smape: 5.7585 - coeff_determination: 0.8762WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 45: loss improved from 0.00402 to 0.00387, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 23s 129ms/step - loss: 0.0039 - rmse: 0.0615 - mae: 0.0433 - smape: 5.7552 - coeff_determination: 0.8764\n",
      "Epoch 46/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0040 - rmse: 0.0623 - mae: 0.0437 - smape: 5.7702 - coeff_determination: 0.8747WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00387\n",
      "175/175 [==============================] - 23s 130ms/step - loss: 0.0040 - rmse: 0.0622 - mae: 0.0437 - smape: 5.7705 - coeff_determination: 0.8745\n",
      "Epoch 47/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0039 - rmse: 0.0620 - mae: 0.0433 - smape: 5.7289 - coeff_determination: 0.8755WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00387\n",
      "175/175 [==============================] - 23s 129ms/step - loss: 0.0039 - rmse: 0.0620 - mae: 0.0433 - smape: 5.7277 - coeff_determination: 0.8756\n",
      "Epoch 48/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0039 - rmse: 0.0615 - mae: 0.0429 - smape: 5.6988 - coeff_determination: 0.8771WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00387\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 0.0039 - rmse: 0.0615 - mae: 0.0429 - smape: 5.6972 - coeff_determination: 0.8772\n",
      "Epoch 49/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0038 - rmse: 0.0612 - mae: 0.0426 - smape: 5.6775 - coeff_determination: 0.8769WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 49: loss improved from 0.00387 to 0.00382, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 0.0038 - rmse: 0.0612 - mae: 0.0426 - smape: 5.6777 - coeff_determination: 0.8763\n",
      "Epoch 50/50\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.0038 - rmse: 0.0607 - mae: 0.0424 - smape: 5.6546 - coeff_determination: 0.8800WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 50: loss improved from 0.00382 to 0.00378, saving model to checkpoint\\Transformer.test Wed Dec 07 16 58 36 2022.hdf5\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 0.0038 - rmse: 0.0608 - mae: 0.0425 - smape: 5.6568 - coeff_determination: 0.8798\n",
      "75/75 [==============================] - 3s 39ms/step\n",
      "[[0.72266227 0.7261319  0.7238485  0.7247149  0.72169745 0.7202811 ]\n",
      " [0.72361904 0.73096114 0.7258931  0.72371054 0.72329605 0.7211752 ]\n",
      " [0.7474161  0.7483354  0.748674   0.74423337 0.74507594 0.74338037]\n",
      " ...\n",
      " [0.1615597  0.17660332 0.19038938 0.20664288 0.21469082 0.24048637]\n",
      " [0.16331352 0.17725098 0.19390336 0.19942787 0.21877593 0.23850109]\n",
      " [0.14897935 0.17539734 0.17449594 0.18770549 0.20663458 0.21867612]]\n"
     ]
    }
   ],
   "source": [
    "## Testing the Transformer\n",
    "import time\n",
    "start_time = time.time()\n",
    "look_back = 12\n",
    "tr = Transformer()\n",
    "tr.train(X_train_reshaped,y_train_reshaped)\n",
    "a=tr.evaluate(X_test_reshaped,y_test_reshaped)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "726fffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max=np.array(max)\n",
    "min=np.array(min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9078775a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[300.43575495 301.68135786 300.86161929 301.1726402  300.08938444\n",
      "  299.58092356]\n",
      " [300.77923673 303.41505069 301.5956158  300.81208277 300.66328061\n",
      "  299.90189457]\n",
      " [309.32237238 309.65241617 309.77395719 308.17977977 308.48226285\n",
      "  307.87355202]\n",
      " ...\n",
      " [ 98.99993265 104.4005909  109.34978737 115.18479429 118.07400416\n",
      "  127.3346063 ]\n",
      " [ 99.62955473 104.6331023  110.61130509 112.59460637 119.54055816\n",
      "  126.62189017]\n",
      " [ 94.48358698 103.9676438  103.64404082 108.38626984 115.18181461\n",
      "  119.5047271 ]]\n"
     ]
    }
   ],
   "source": [
    "#Denormalizing prediction\n",
    "forec1=a*(max-min)+min\n",
    "print(forec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24ffe53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[299.99998331 308.99998909 311.99999815 312.99999404 311.99999815\n",
      "  311.00000226]\n",
      " [308.99998909 311.99999815 312.99999404 311.99999815 311.00000226\n",
      "  313.99998993]\n",
      " [311.99999815 312.99999404 311.99999815 311.00000226 313.99998993\n",
      "  317.99999487]\n",
      " ...\n",
      " [ 87.0000034   85.99999681  76.99999905  70.99999698  74.00000069\n",
      "   71.99999822]\n",
      " [ 85.99999681  76.99999905  70.99999698  74.00000069  71.99999822\n",
      "   78.00000029]\n",
      " [ 76.99999905  70.99999698  74.00000069  71.99999822  78.00000029\n",
      "   78.99999618]]\n"
     ]
    }
   ],
   "source": [
    "#Denomalizing the actual values\n",
    "actual=ytest*(max-min)+min\n",
    "print(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb930566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 15.091343108003548\n"
     ]
    }
   ],
   "source": [
    "#Computing the RMSE\n",
    "forec1=np.array(forec1)\n",
    "actual=np.array(actual)\n",
    "diff=actual-forec1\n",
    "#print(diff.shape)\n",
    "#np.sqrt(np.mean((diff)**2,axis=0))\n",
    "print(\"RMSE:\",np.sqrt(np.mean((diff)**2,axis=0)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a76e84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1125.688708782196 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
